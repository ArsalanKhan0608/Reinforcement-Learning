{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Incremental Average To Estimate Action Values\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, we'll explore the concept of using incremental averages to estimate action values in the context of Reinforcement Learning. This technique is particularly useful for solving problems where the environment is non-stationary, meaning the probabilities and rewards can change over time.\n",
        "\n",
        "## Importance\n",
        "\n",
        "Incremental averaging is crucial for adapting to changing environments. It allows the agent to give more weight to recent experiences, making it more responsive to changes.\n",
        "\n",
        "## Drawbacks\n",
        "\n",
        "While incremental averaging is good for non-stationary environments, it may not be the best choice for stationary environments where the probabilities are constant. In such cases, giving more weight to recent experiences might lead to suboptimal decisions.\n",
        "\n",
        "## Real-world Applications\n",
        "\n",
        "Incremental averaging techniques are widely used in online recommendation systems, stock trading algorithms, and adaptive control systems.\n",
        "\n",
        "Let's dive in!"
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "6342a6da-4689-49a1-83a1-88b8978bca3f"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulated slot machines (bandit arms)\n",
        "true_means = [0.1, 0.5, 0.8]\n",
        "\n",
        "# Function to pull an arm\n",
        "def pull_arm(mean):\n",
        "    return np.random.normal(mean, 1)\n",
        "\n",
        "# Incremental Average Algorithm\n",
        "def incremental_average(true_means, alpha=0.1, n_rounds=100):\n",
        "    estimated_means = [0, 0, 0]\n",
        "    n_pulls = [0, 0, 0]\n",
        "    rewards = []\n",
        "    for _ in range(n_rounds):\n",
        "        arm = np.argmax(estimated_means)\n",
        "        reward = pull_arm(true_means[arm])\n",
        "        rewards.append(reward)\n",
        "        n_pulls[arm] += 1\n",
        "        estimated_means[arm] += alpha * (reward - estimated_means[arm])\n",
        "    return np.sum(rewards), rewards\n",
        "\n",
        "# Run the Incremental Average Algorithm\n",
        "total_reward, rewards = incremental_average(true_means)\n",
        "total_reward, np.mean(rewards)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "(73.78094680895728, 0.7378094680895728)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "end_time": "2023-10-11T11:31:06.967808+00:00",
          "start_time": "2023-10-11T11:31:06.639630+00:00"
        }
      },
      "id": "0e90273c-6602-48c2-b12c-4b7d787bed7a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Explanation\n",
        "\n",
        "1. **Import Libraries**: We import `numpy` for numerical operations and `matplotlib.pyplot` for plotting.\n",
        "\n",
        "2. **Simulated Bandit Arms**: We simulate three slot machines (bandit arms) with true mean rewards of 0.1, 0.5, and 0.8.\n",
        "\n",
        "3. **Pull Arm Function**: A function `pull_arm(mean)` that simulates pulling an arm and returns a reward from a normal distribution centered around the mean.\n",
        "\n",
        "4. **Incremental Average Algorithm**: The function `incremental_average(true_means, alpha=0.1, n_rounds=100)` implements the incremental average algorithm. It takes the true means of the arms, a learning rate `alpha`, and the number of rounds `n_rounds` as inputs.\n",
        "\n",
        "5. **Run Algorithm**: We run the algorithm and store the total reward and individual rewards.\n",
        "\n",
        "## Output Interpretation\n",
        "\n",
        "The total reward obtained after 100 rounds is approximately 73.78, and the average reward per round is approximately 0.74. This shows that the incremental average algorithm is effective in maximizing the reward."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "b4e91d22-1b42-4f01-b81c-f360b6c6a0fa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: Effect of Learning Rate\n",
        "\n",
        "### Question\n",
        "\n",
        "How does the learning rate (`alpha`) affect the performance of the incremental average algorithm?\n",
        "\n",
        "### Instructions\n",
        "\n",
        "1. Run the incremental average algorithm with different values of `alpha` (e.g., 0.01, 0.1, 0.5, 1).\n",
        "2. Plot the total rewards for each value of `alpha`.\n",
        "\n",
        "### Exercise 2: Effect of Number of Rounds\n",
        "\n",
        "### Question\n",
        "\n",
        "How does the number of rounds (`n_rounds`) affect the performance of the incremental average algorithm?\n",
        "\n",
        "### Instructions\n",
        "\n",
        "1. Run the incremental average algorithm with different numbers of rounds (e.g., 50, 100, 200, 500).\n",
        "2. Plot the total rewards for each number of rounds.\n",
        "\n",
        "### Exercise 3: Comparison with Greedy Algorithm\n",
        "\n",
        "### Question\n",
        "\n",
        "How does the incremental average algorithm compare with the greedy algorithm in terms of total rewards?\n",
        "\n",
        "### Instructions\n",
        "\n",
        "1. Implement the greedy algorithm.\n",
        "2. Run both the incremental average and greedy algorithms and compare the total rewards."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "4b240f0e-5001-4261-adcd-f5c1dea800d3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1: Effect of Learning Rate\n",
        "\n",
        "alpha_values = [0.01, 0.1, 0.5, 1]\n",
        "total_rewards_alpha = []\n",
        "\n",
        "for alpha in alpha_values:\n",
        "    total_reward, _ = incremental_average(true_means, alpha)\n",
        "    total_rewards_alpha.append(total_reward)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar([str(a) for a in alpha_values], total_rewards_alpha, color='blue')\n",
        "plt.xlabel('Alpha Values')\n",
        "plt.ylabel('Total Rewards')\n",
        "plt.title('Effect of Learning Rate on Total Rewards')\n",
        "plt.show()\n",
        "\n",
        "# Exercise 2: Effect of Number of Rounds\n",
        "\n",
        "n_rounds_values = [50, 100, 200, 500]\n",
        "total_rewards_rounds = []\n",
        "\n",
        "for n in n_rounds_values:\n",
        "    total_reward, _ = incremental_average(true_means, n_rounds=n)\n",
        "    total_rewards_rounds.append(total_reward)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar([str(n) for n in n_rounds_values], total_rewards_rounds, color='green')\n",
        "plt.xlabel('Number of Rounds')\n",
        "plt.ylabel('Total Rewards')\n",
        "plt.title('Effect of Number of Rounds on Total Rewards')\n",
        "plt.show()\n",
        "\n",
        "# Exercise 3: Comparison with Greedy Algorithm\n",
        "\n",
        "# Greedy Algorithm\n",
        "def greedy(true_means, n_rounds=100):\n",
        "    estimated_means = [0, 0, 0]\n",
        "    n_pulls = [0, 0, 0]\n",
        "    rewards = []\n",
        "    for _ in range(n_rounds):\n",
        "        arm = np.argmax(estimated_means)\n",
        "        reward = pull_arm(true_means[arm])\n",
        "        rewards.append(reward)\n",
        "        n_pulls[arm] += 1\n",
        "        estimated_means[arm] = ((n_pulls[arm] - 1) * estimated_means[arm] + reward) / n_pulls[arm]\n",
        "    return np.sum(rewards)\n",
        "\n",
        "total_reward_greedy = greedy(true_means)\n",
        "total_reward_incremental = incremental_average(true_means)[0]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(['Greedy', 'Incremental Average'], [total_reward_greedy, total_reward_incremental], color='red')\n",
        "plt.xlabel('Algorithm')\n",
        "plt.ylabel('Total Rewards')\n",
        "plt.title('Comparison of Greedy and Incremental Average Algorithms')\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "https://production-noteable-gate-kernel-outputs-k066hgvt.s3.amazonaws.com/notebook-kernel-e10ce669c65f4836b917/017b593f-5bf8-4b48-9d8b-f0820c7c2bb8/ea411d08-fe20-4c71-afd1-28d50731cfec/content/a693e97d-775b-40e1-a8e4-96e87abd844d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIA4CXUTGDVJA77BZVN%2F20231012%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231012T042557Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCqbugtAHois1lK7yf05vA1oHHuBGMg16lWTRbfbL5ZHQIgKqY7fFlpI23OMTan%2BstJD%2F0p5wMk2JP57wTtpuGH4D0q%2FwQI%2Ff%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARADGgw4MzA1MTUzOTI3NDYiDFdUUKvPbo3Ou6BRqCrTBLeIrMXoH400%2FPW97QB5YCs18LqXqOYphVAn%2FbdKiS7VKgDoJSoOY9hmmTmQe4zLP8OYO2NKbfCqb5HgrZaK1CeRJOLT%2BzJUjY4SucqQ2w%2F8gE7FUyTReTRMrUBIjac7b6qhYhQahKfKpfL6MfSKL3FpGxlgcNlxW32cWzJ6VQ19TvToh9WrzpEewY%2BUAJWi0ENF6CmOy9ikkZJ8PS6A3abcJzelePR2hVhEAXrxu0UaMocrn5lghIaiVMSMiwv3eMHMiu79Rb7OR93ZaStKW056TQsiv8kAXLWpStEFHW3wYlin0cV4hMy7ZlTfbZZa%2FUOvsoczC5Ish5%2FprV0NQPFDctH2syUw5OFL8xmTOnYydmb02C2J6juP5qf3NElk4NOkIuBPZy7q3xD5lQ6lbZto%2FngZGu6l6MpECo2V4N%2FG7NPs5iDOKZ%2FoNP9PUWj0vj9%2BdrbVi8ssmWvx2ngkkimTlLaiiLMtuOl6y4aftY7H1woVC%2BH2sxzibrXeEzhn0c%2FlkLdIqXKj7oaPTyPAHNm3BQIf3Lib4C7FLYKoz3iQvNakCFSzzWP%2BET4FcLRqEqVQBKe%2B3w1EFnj0GLoO1QRgoVA4lQkMPq6VdBnvQ0llGE5peZ1tqrg9lDUJteQHc86w5kWDCAN7BmA%2FxrPUDZ9BMXx%2BPfO%2Bx3cMRRL5PestR49vcvgpK2pXpjQTSEUICkQNvcBj99n8QzgjVxCruds0uBdx5wOwXVW0kcOSFPYPoIAuXOy%2B8adh4bqgqMGTLpp08HciKZjUJpYLsmpEx9ozyFIwg%2BadqQY6mgH4em12oDnk83SRy11xWQPUbuRAA4v60in4LPmEq2hUGf4FZ5ASUciPHirxYuv0NjfGrBMLjhtkrw6IZiFR6kWcx9udwJI80Rw02uD0NXa74ZUW6Uy5aKmuvPMGUn0iM5Gcyu%2B2%2FQCwgT9f70FjmGHPg5EhovoZP2O10O%2FLMMZTc3LBfOzNIUzjscL2ie7zohq7Fw1Unv%2BHTrNe&X-Amz-Signature=ad529fb13f958e853ce9789242f2476e21f0da6d43b770de244b1d39322dc282"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "https://production-noteable-gate-kernel-outputs-k066hgvt.s3.amazonaws.com/notebook-kernel-e10ce669c65f4836b917/017b593f-5bf8-4b48-9d8b-f0820c7c2bb8/d6e4ce50-37a2-45c4-8c1a-2e565f0dff7d/content/1b480ab9-38ec-4d0c-927f-128f623a3797?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIA4CXUTGDVJA77BZVN%2F20231012%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231012T042557Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCqbugtAHois1lK7yf05vA1oHHuBGMg16lWTRbfbL5ZHQIgKqY7fFlpI23OMTan%2BstJD%2F0p5wMk2JP57wTtpuGH4D0q%2FwQI%2Ff%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARADGgw4MzA1MTUzOTI3NDYiDFdUUKvPbo3Ou6BRqCrTBLeIrMXoH400%2FPW97QB5YCs18LqXqOYphVAn%2FbdKiS7VKgDoJSoOY9hmmTmQe4zLP8OYO2NKbfCqb5HgrZaK1CeRJOLT%2BzJUjY4SucqQ2w%2F8gE7FUyTReTRMrUBIjac7b6qhYhQahKfKpfL6MfSKL3FpGxlgcNlxW32cWzJ6VQ19TvToh9WrzpEewY%2BUAJWi0ENF6CmOy9ikkZJ8PS6A3abcJzelePR2hVhEAXrxu0UaMocrn5lghIaiVMSMiwv3eMHMiu79Rb7OR93ZaStKW056TQsiv8kAXLWpStEFHW3wYlin0cV4hMy7ZlTfbZZa%2FUOvsoczC5Ish5%2FprV0NQPFDctH2syUw5OFL8xmTOnYydmb02C2J6juP5qf3NElk4NOkIuBPZy7q3xD5lQ6lbZto%2FngZGu6l6MpECo2V4N%2FG7NPs5iDOKZ%2FoNP9PUWj0vj9%2BdrbVi8ssmWvx2ngkkimTlLaiiLMtuOl6y4aftY7H1woVC%2BH2sxzibrXeEzhn0c%2FlkLdIqXKj7oaPTyPAHNm3BQIf3Lib4C7FLYKoz3iQvNakCFSzzWP%2BET4FcLRqEqVQBKe%2B3w1EFnj0GLoO1QRgoVA4lQkMPq6VdBnvQ0llGE5peZ1tqrg9lDUJteQHc86w5kWDCAN7BmA%2FxrPUDZ9BMXx%2BPfO%2Bx3cMRRL5PestR49vcvgpK2pXpjQTSEUICkQNvcBj99n8QzgjVxCruds0uBdx5wOwXVW0kcOSFPYPoIAuXOy%2B8adh4bqgqMGTLpp08HciKZjUJpYLsmpEx9ozyFIwg%2BadqQY6mgH4em12oDnk83SRy11xWQPUbuRAA4v60in4LPmEq2hUGf4FZ5ASUciPHirxYuv0NjfGrBMLjhtkrw6IZiFR6kWcx9udwJI80Rw02uD0NXa74ZUW6Uy5aKmuvPMGUn0iM5Gcyu%2B2%2FQCwgT9f70FjmGHPg5EhovoZP2O10O%2FLMMZTc3LBfOzNIUzjscL2ie7zohq7Fw1Unv%2BHTrNe&X-Amz-Signature=36f82e6773c9f8f738123d9a83adb30d571004da839ea12973a7d0a1f8514310"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "https://production-noteable-gate-kernel-outputs-k066hgvt.s3.amazonaws.com/notebook-kernel-e10ce669c65f4836b917/017b593f-5bf8-4b48-9d8b-f0820c7c2bb8/c1211898-121a-425e-8ba8-164c0fea346d/content/bdeeea82-3a6d-4f10-bdc9-b4e9c2f011a7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIA4CXUTGDVJA77BZVN%2F20231012%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231012T042557Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCqbugtAHois1lK7yf05vA1oHHuBGMg16lWTRbfbL5ZHQIgKqY7fFlpI23OMTan%2BstJD%2F0p5wMk2JP57wTtpuGH4D0q%2FwQI%2Ff%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARADGgw4MzA1MTUzOTI3NDYiDFdUUKvPbo3Ou6BRqCrTBLeIrMXoH400%2FPW97QB5YCs18LqXqOYphVAn%2FbdKiS7VKgDoJSoOY9hmmTmQe4zLP8OYO2NKbfCqb5HgrZaK1CeRJOLT%2BzJUjY4SucqQ2w%2F8gE7FUyTReTRMrUBIjac7b6qhYhQahKfKpfL6MfSKL3FpGxlgcNlxW32cWzJ6VQ19TvToh9WrzpEewY%2BUAJWi0ENF6CmOy9ikkZJ8PS6A3abcJzelePR2hVhEAXrxu0UaMocrn5lghIaiVMSMiwv3eMHMiu79Rb7OR93ZaStKW056TQsiv8kAXLWpStEFHW3wYlin0cV4hMy7ZlTfbZZa%2FUOvsoczC5Ish5%2FprV0NQPFDctH2syUw5OFL8xmTOnYydmb02C2J6juP5qf3NElk4NOkIuBPZy7q3xD5lQ6lbZto%2FngZGu6l6MpECo2V4N%2FG7NPs5iDOKZ%2FoNP9PUWj0vj9%2BdrbVi8ssmWvx2ngkkimTlLaiiLMtuOl6y4aftY7H1woVC%2BH2sxzibrXeEzhn0c%2FlkLdIqXKj7oaPTyPAHNm3BQIf3Lib4C7FLYKoz3iQvNakCFSzzWP%2BET4FcLRqEqVQBKe%2B3w1EFnj0GLoO1QRgoVA4lQkMPq6VdBnvQ0llGE5peZ1tqrg9lDUJteQHc86w5kWDCAN7BmA%2FxrPUDZ9BMXx%2BPfO%2Bx3cMRRL5PestR49vcvgpK2pXpjQTSEUICkQNvcBj99n8QzgjVxCruds0uBdx5wOwXVW0kcOSFPYPoIAuXOy%2B8adh4bqgqMGTLpp08HciKZjUJpYLsmpEx9ozyFIwg%2BadqQY6mgH4em12oDnk83SRy11xWQPUbuRAA4v60in4LPmEq2hUGf4FZ5ASUciPHirxYuv0NjfGrBMLjhtkrw6IZiFR6kWcx9udwJI80Rw02uD0NXa74ZUW6Uy5aKmuvPMGUn0iM5Gcyu%2B2%2FQCwgT9f70FjmGHPg5EhovoZP2O10O%2FLMMZTc3LBfOzNIUzjscL2ie7zohq7Fw1Unv%2BHTrNe&X-Amz-Signature=05cf6c06048bcdafa1da2fbf461ea52ccbaaa79f3664a3968f74022fb47b5845"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "end_time": "2023-10-11T11:33:00.775963+00:00",
          "start_time": "2023-10-11T11:32:59.869517+00:00"
        }
      },
      "id": "017b593f-5bf8-4b48-9d8b-f0820c7c2bb8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise Solutions and Interpretations\n",
        "\n",
        "### Exercise 1: Effect of Learning Rate\n",
        "\n",
        "As we can see from the first plot, the learning rate (`alpha`) has a significant impact on the total rewards. Higher values of `alpha` tend to yield higher total rewards. This is because a higher learning rate allows the agent to adapt more quickly to the environment.\n",
        "\n",
        "### Exercise 2: Effect of Number of Rounds\n",
        "\n",
        "The second plot shows that the number of rounds (`n_rounds`) also affects the total rewards. More rounds generally lead to higher total rewards as the agent gets more opportunities to learn and adapt.\n",
        "\n",
        "### Exercise 3: Comparison with Greedy Algorithm\n",
        "\n",
        "The third plot compares the total rewards obtained by the greedy algorithm and the incremental average algorithm. Both algorithms perform similarly, but the incremental average algorithm has the advantage of being more adaptive to non-stationary environments."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "8f7bded1-7c3c-4eb7-89f2-370b676291b8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1: Effect of Learning Rate\n",
        "\n",
        "alpha_values = [0.01, 0.1, 0.5, 1]\n",
        "total_rewards_alpha = []\n",
        "\n",
        "for alpha in alpha_values:\n",
        "    total_reward, _ = incremental_average(true_means, alpha)\n",
        "    total_rewards_alpha.append(total_reward)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar([str(a) for a in alpha_values], total_rewards_alpha, color='blue')\n",
        "plt.xlabel('Alpha Values')\n",
        "plt.ylabel('Total Rewards')\n",
        "plt.title('Effect of Learning Rate on Total Rewards')\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "https://production-noteable-gate-kernel-outputs-k066hgvt.s3.amazonaws.com/notebook-kernel-e10ce669c65f4836b917/9c2ea6dc-9efc-433b-9923-81e11aa42d67/8789a126-8b8c-4598-a42f-5149e8e36a07/content/70241347-4bc2-403e-8b5a-1702d56efd40?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIA4CXUTGDVJBGBV6G6%2F20231012%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231012T042557Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCU5lVQMsM4x7hSKLSQ2lBz3%2BvzOZuV7aduDJasIuA0DQIgdQLsxtw%2BmwKkDkIKUSgILFBOuwFRhzDqq71I8ymyK34q%2FwQI%2Ff%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARADGgw4MzA1MTUzOTI3NDYiDN2tWIAnZ1QQ5EmOzCrTBEUjNkiFC1%2B7fAq%2FY2tIy%2FmH4qXDNAzVNm0GNY92U%2BbK4LQpjkhLSytq%2F09FAPF2HKdl9uCSBRXqwC5Itqp5wl%2Bwva0RyL4a3meUsbnAs2QyWqUC5aAE5%2FbXV%2Bf35WU0S5AdZ6CWavKKHwtGJDC%2FuGcHcY3WuMuIxlXXWeDhWrkWBvAtk4sKcRNfLocrCQnAHuI353R8GtgtNVvZk6F35E3jCs%2FosD6Bx7NvNXPjGgwGb%2FLtEUErS2uKmGWu5QYW68WlQNUhSyle50d6szCoDkJJrij8BctyBE%2F3FjXctU30ZGGbNPokjltvdANQ7K8gHqrS%2BbejIeJD99eGUQOh5f7%2BHgp6aiH8UL5a%2F5gF%2F1VYxPzBzvUFJi5HzYqNSumiVTGoBP%2BCz6iwia08CjPdYWVvN1h2ApWksD%2BLZRVixQBmbsAKhcZ7V3QY%2BAGxbketxLolWpo7lfbaqcxUJTQKtrAvHh2nPG8OEVZfh59WLHOKuj%2F60w7q5VdhEgWUbQIZTGnE3pel5MvQL%2FYSpW6go1aIof3YMP0HVpNcMmSDTT30xuhrOjb1FWsNwTAbIHa%2BnVieNIVEiLVGsooLKbV3ldnE7AKJe6J%2BFKhyNM3K6KHOCphcYxUmjUjUdgTj0MeDrHiZEO62mlWD3jky5%2FvYm8eaUA%2FBZpexnGNeRgmxf73fQTIwutbhoApglfC7HOj3ZCjGAo7226QADH6qz6ZzIrfRp3tUBclLV%2BQotIK68Zi%2BUzQd3KuW1nAJPELfdCWeYAAp0u%2B%2FkMm8GKpeM0L3qFrF4lUw9tmdqQY6mgHVbEVKVoaDC0EaiA%2B92SymfvV083dRtkaKyEeNIKPmiKdnTAJ0Tn1eNyB9an5hXbTh6Ov9Lupye%2B19e7GWrOd7leGslNSn1sAsktObabSFPaNG9K6N0lNDa%2FO7xaji7%2BhiRdsliHJxHbU6Gk9oH5YDLitWaaykgwYAq5X1Al%2Buk4lqvMiyUITTBGJ4MfuKqJxXqQN8ZN5OVz8E&X-Amz-Signature=85e222cb3277ccf4989971a092ccc420e9d218e1744a5541bc6deb0d45c580d4"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "end_time": "2023-10-11T11:34:09.180968+00:00",
          "start_time": "2023-10-11T11:34:08.835461+00:00"
        }
      },
      "id": "9c2ea6dc-9efc-433b-9923-81e11aa42d67"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1: Solution and Interpretation\n",
        "\n",
        "As we can see from the plot, the learning rate (`alpha`) has a significant impact on the total rewards. Higher values of `alpha` (e.g., 0.5 and 1) result in lower total rewards compared to lower values (e.g., 0.01 and 0.1). This suggests that a smaller learning rate allows the algorithm to better adapt to the environment and maximize rewards.\n",
        "\n",
        "Now, let's move on to Exercise 2."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "e73b315c-e158-4e2c-b5ef-1d6c4bc54012"
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2: Effect of Number of Rounds\n",
        "\n",
        "n_rounds_values = [50, 100, 200, 500]\n",
        "total_rewards_rounds = []\n",
        "\n",
        "for n in n_rounds_values:\n",
        "    total_reward, _ = incremental_average(true_means, n_rounds=n)\n",
        "    total_rewards_rounds.append(total_reward)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar([str(n) for n in n_rounds_values], total_rewards_rounds, color='green')\n",
        "plt.xlabel('Number of Rounds')\n",
        "plt.ylabel('Total Rewards')\n",
        "plt.title('Effect of Number of Rounds on Total Rewards')\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "https://production-noteable-gate-kernel-outputs-k066hgvt.s3.amazonaws.com/notebook-kernel-e10ce669c65f4836b917/d4e6c69d-d4b8-4ebc-8c11-a862a26d9e81/3ede875f-4112-4ab6-aba3-ba192a8fbd11/content/8a290e68-194c-470c-acde-559c467b3dc0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIA4CXUTGDVC3FQBZP2%2F20231012%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231012T042557Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCICoabmzHyIYZmBttSoh27dUKxoAx3Ap0kE1%2F3YzHQR%2BCAiEA4nusxdgD8Rkq14Kj8fnD4joo8MFHDZrJkQEVb4vvBb8q%2FwQI%2Ff%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARADGgw4MzA1MTUzOTI3NDYiDAjXPsy%2B3sNOmVF3%2FSrTBI9r5mo1mnBlcVrKm3CvK2fji1EF%2BvhYWefXEWSREqr9NqO6K2agDaETX36ZVaOMSe%2F6BFDBsCwmmExTOYvdhnqLuNvTmA1AhwaS0n%2BsflAoZ9L8OhoZYisA7OSQqqwLMDlXerVIf4PK4xur8gQ6vpKSMZ61AfUHDo0Q4YQugUf%2Brm%2F3P5dTUW09jWZaOoPPB%2B2cYI76EeaGFws0nziUuS3QupgE3oE6HqW8C%2FxTjf17xgfCbUJ%2Bla%2FzqmDL8f%2BozHacOWsZe%2BmwcK43NQ2JIpRBKdxFmGmqvYVAU2zb%2BBAshvewLytyr507nnCZW0mdPayqCTqJjJA73mEiHW%2BF9gylswwDPhbPk6p9Dx54wkIAUQhQIA8WMzp7LmtPz51%2FShKh3yeLT3LkiEXqxaS8PLzNvxTY1y%2BmjFqnCFCQ5%2B6BBehOfAMTXoji5sSgWH7RAyh1jRemSUO3aBEZgDhJJ4ZV8W2%2BwadDx3ppsuwjUCaF%2F8QUPFiP4YOvidOzUBoRccN%2FXd7z3aaGRO3%2FpAcIR0XTO4GTS%2FLU%2Fspl%2FRR2bz9bJHo8ZdX2tmyGMIXssMzNwyzWufkFVjs0CNBALxS%2FV1mTZQPcNXH%2B5bv1klNobHJ7ArYk0YsNJEPHtnYtsoeY40O5UwfNkq4BF041I7IV8KdjN3fRFgxTDRsGdIvruac%2BO0EbMdoaytTEgPug529%2BpuECnsm%2Fz6jZ067TpUnA0k1z3OHjL9DuZZkjyfXV4Fi6y%2FjIDIwQfq06WoAWxuftR44CDtGVAI%2Fj%2BCmqix8QM9q8sM0w3eKdqQY6mgHBsaMNJub3FxkoUyt4670ybuc8j%2BE3%2Bjs3wCk8KgGcdE7h7rzjfom6BXzkAKHm7jd0aEo6ck03nrrI5Zt0u22cHU%2BSeFtSi1osD0BPwds80Crpkx3FKUXnXVm28%2FtcBdW0M5xa7ji4AUBk9rtD5r5VekTdw1Pn76m%2BdVXSj1I5H2TzNCV1t7k3trHdGESauOmoeXlkOfUZClSY&X-Amz-Signature=62417caff908f6f39342e100c22fcbb4b4be0f9f2387739b5a91c6376fbd94cd"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "end_time": "2023-10-11T11:34:51.561010+00:00",
          "start_time": "2023-10-11T11:34:51.185157+00:00"
        }
      },
      "id": "d4e6c69d-d4b8-4ebc-8c11-a862a26d9e81"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2: Solution and Interpretation\n",
        "\n",
        "The plot shows that the total rewards increase as the number of rounds (`n_rounds`) increases. This is expected as more rounds give the algorithm more opportunities to learn and adapt, thereby maximizing the total rewards.\n",
        "\n",
        "Next, let's proceed to Exercise 3."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "dc4120f9-5004-496a-976a-434e8c862aa4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 3: Comparison with Greedy Algorithm\n",
        "\n",
        "# Greedy Algorithm\n",
        "def greedy(true_means, n_rounds=100):\n",
        "    estimated_means = [0, 0, 0]\n",
        "    n_pulls = [0, 0, 0]\n",
        "    rewards = []\n",
        "    for _ in range(n_rounds):\n",
        "        best_arm = np.argmax(estimated_means)\n",
        "        reward = pull_arm(true_means[best_arm])\n",
        "        rewards.append(reward)\n",
        "        n_pulls[best_arm] += 1\n",
        "        estimated_means[best_arm] = ((n_pulls[best_arm] - 1) * estimated_means[best_arm] + reward) / n_pulls[best_arm]\n",
        "    return np.sum(rewards)\n",
        "\n",
        "# Run both algorithms\n",
        "total_reward_greedy = greedy(true_means)\n",
        "total_reward_incremental = incremental_average(true_means)[0]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(['Greedy', 'Incremental Average'], [total_reward_greedy, total_reward_incremental], color=['red', 'blue'])\n",
        "plt.xlabel('Algorithm')\n",
        "plt.ylabel('Total Rewards')\n",
        "plt.title('Comparison of Greedy and Incremental Average Algorithms')\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "https://production-noteable-gate-kernel-outputs-k066hgvt.s3.amazonaws.com/notebook-kernel-e10ce669c65f4836b917/3912b169-1a09-431c-9353-41a8e9539e48/cd062f56-48dd-4fa9-9974-cf830098ccc6/content/06a8bd2f-1da0-406e-a96c-474345c239ad?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIA4CXUTGDVDUZDZOWF%2F20231012%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231012T042557Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIFQyiFGw23%2F6DWMzcjo22kbuXsSdJH%2BMqBku7rYSPuFPAiEAqn3uzG7sqqm1S2eOiK2yz%2FvyVjvOhFrrELcb05yX2Boq%2FwQI%2Ff%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARADGgw4MzA1MTUzOTI3NDYiDGMrVAzsWrSopbzeVCrTBJaCQg1LEucYAZsA126DSVFcp8Jjm%2FSgL1NfIreE4ZvXOYqsuD7Dub4J72dvac%2F2YBfQS%2B45zXI8L0xewwHgbfnqVcFeySuvSIQZK1f%2F4njDLxRZp2YYs9xXk6IwfNeKWaGmIT5fjxnb7sjPga5aCSVyMiKFeeHv0%2BoWCT%2BY6%2BPls2a9y%2BD9yaI7Vh1RrqIe%2FcvrzsJBFVZpxpRbOim8i50CylcG6qxXVJUPNb5qc23sXcMHzrt1SjhYmQHfBvhHMEwfzYhgq7wsDnFDDcrZYQW6jRnJ7jvY8PA0bv%2FWol9c38BfMsVFwmaPvV3LLo%2BugGhyAIU75N0V9iTeVC%2FPzI0SdXGwo%2FlTX%2FGfky4sx0cT00RmF4zOXKDWvycRKc6v75BQHEfEw5KoD2pKgiyVPK69MTNZ2dGUzSPbozxA5kqd0grMbQGPkM3ocTpzqwzko%2FM8%2B2jOLoFMm1hUtVrF2h2PWE0aJqDP%2FvP1V4Xzbong4HhoS7fX1t9ign05IQDflwbF4NSnC%2F0QUGDYXl6mB6a3%2FrqcR4Pf3BG3%2B%2FMTqVuLQOzkNeKaF%2FYpgSrVJZBrUl0bf%2F5SklKzueyA62wqn%2Bn3XYvZcG2guQ5oHrLtkuWmhzQpf9K9JaVH8VyId%2F4HKi4CsPBpdUhA6HvRfgjApKMoAN4EIvt9RNEDSePaGmBS4ProcF4AftIV3u3UicfSG2WlMj3p0G7Y7R3M1ze2bk9BwPwAIcRoyg3TwKh8o%2BdJpyfLKIIiCnddj8%2BemwPUmke7YfVNyVHeYItw%2BuGtC26BMSMwu%2BedqQY6mgGYK3krY%2Bwq4EfOstOODqnW9CbjhXEvnOQE9ODs9RIkaydJe%2F%2FC64HE6lHPEXnClaqvKmdnT1DI3GIx3JSBGZ2VKg67d9JlnwNB2cp4xtzGyHfQzNWMzzqGwXzZpN30M%2BpfTkYZb4CjuSo%2F9RzjugyuGFNEr%2FyENweWCEgr5YV%2F2xKdMDTXLwHg9FaYTemTaMyYO%2BNIPojat9PQ&X-Amz-Signature=a2f62e0c0684b97ebc6334ddac9187c6bf09302a9b05b359667ac969d5d46efe"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        },
        "ExecuteTime": {
          "end_time": "2023-10-11T11:35:36.857410+00:00",
          "start_time": "2023-10-11T11:35:36.535760+00:00"
        }
      },
      "id": "3912b169-1a09-431c-9353-41a8e9539e48"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3: Solution and Interpretation\n",
        "\n",
        "The bar chart compares the total rewards obtained by the Greedy and Incremental Average algorithms. As we can see, the Incremental Average algorithm performs slightly better than the Greedy algorithm in terms of total rewards.\n",
        "\n",
        "This concludes our exploration of using Incremental Average to estimate action values. We've learned its importance, drawbacks, and applications, and we've also conducted exercises to deepen our understanding."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "d5a93d6d-b6be-4513-91aa-fac41f318998"
    }
  ],
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "8e9f926a-ce11-5aa9-95c1-bd26017668fc",
        "openai_ephemeral_user_id": "d97cd37a-db81-523a-bf0d-36f1aca6eae2",
        "openai_subdivision1_iso_code": "PK-IS"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
    },
    "selected_hardware_size": "small",
    "noteable": {
      "last_delta_id": "c87cf8d1-78c2-4774-a3a8-c32820eae88f"
    },
    "nteract": {
      "version": "noteable@2.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}